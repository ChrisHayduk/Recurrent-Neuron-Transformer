{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNCYEe6cRDd2jE+BqecTbfS"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["First follow the instruction to create a short cut of Chris's recurrent-transformer-models folder to your own drive, https://stackoverflow.com/a/61113429"],"metadata":{"id":"RnR_Kk7PRUU4"}},{"cell_type":"code","source":["from google.colab import drive\n","MODEL_ARTIFACT_GOOGLE_DRIVE_PATH = f\"/content/drive/My Drive/recurrent-transformer-models/model_artifacts\"\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-obMsBa4RE2F","executionInfo":{"status":"ok","timestamp":1702239243212,"user_tz":360,"elapsed":21383,"user":{"displayName":"Gen Li","userId":"08701234808064529813"}},"outputId":"2feb3797-8429-4743-ff74-a5332bebad3d"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_Bm01HoCLEnV","executionInfo":{"status":"ok","timestamp":1702239272196,"user_tz":360,"elapsed":28986,"user":{"displayName":"Gen Li","userId":"08701234808064529813"}},"outputId":"635ef7fc-7098-47c4-8709-a7e0df26e199"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /content/data/MNIST/raw/train-images-idx3-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 9912422/9912422 [00:00<00:00, 83924027.08it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting /content/data/MNIST/raw/train-images-idx3-ubyte.gz to /content/data/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to /content/data/MNIST/raw/train-labels-idx1-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28881/28881 [00:00<00:00, 63688587.71it/s]"]},{"output_type":"stream","name":"stdout","text":["Extracting /content/data/MNIST/raw/train-labels-idx1-ubyte.gz to /content/data/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to /content/data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["\n","100%|██████████| 1648877/1648877 [00:00<00:00, 23345175.10it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting /content/data/MNIST/raw/t10k-images-idx3-ubyte.gz to /content/data/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to /content/data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 4542/4542 [00:00<00:00, 9948056.80it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting /content/data/MNIST/raw/t10k-labels-idx1-ubyte.gz to /content/data/MNIST/raw\n","\n","Epoch 1, Loss: 0.3755399129712887\n"]}],"source":["import os\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torchvision import datasets, transforms\n","from torch.utils.data import DataLoader\n","\n","\n","class SimpleNN(nn.Module):\n","    def __init__(self):\n","        super(SimpleNN, self).__init__()\n","        self.fc1 = nn.Linear(784, 128)  # Assuming input size of 28x28\n","        self.fc2 = nn.Linear(128, 10)   # 10 classes for output\n","\n","    def forward(self, x):\n","        x = x.view(-1, 784)  # Flatten the image\n","        x = torch.relu(self.fc1(x))\n","        x = self.fc2(x)\n","        return x\n","\n","model = SimpleNN()\n","\n","transform = transforms.Compose([transforms.ToTensor(),\n","                                transforms.Normalize((0.5,), (0.5,))])\n","\n","trainset = datasets.MNIST('/content/data', download=True, train=True, transform=transform)\n","trainloader = DataLoader(trainset, batch_size=64, shuffle=True)\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n","\n","epochs = 1\n","for epoch in range(epochs):\n","    running_loss = 0\n","    for images, labels in trainloader:\n","        optimizer.zero_grad()\n","        output = model(images)\n","        loss = criterion(output, labels)\n","        loss.backward()\n","        optimizer.step()\n","        running_loss += loss.item()\n","    print(f\"Epoch {epoch+1}, Loss: {running_loss/len(trainloader)}\")\n","\n","\n","model_name = 'mnist_model_Gen.pth'\n","\n","\n","torch.save(model.state_dict(), f\"{MODEL_ARTIFACT_GOOGLE_DRIVE_PATH}/{model_name}\")\n"]}]}