{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"A100"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NDg2mtIqSa1P","executionInfo":{"status":"ok","timestamp":1702494524956,"user_tz":300,"elapsed":1356,"user":{"displayName":"Christopher Hayduk","userId":"13984500138951800940"}},"outputId":"5f562359-594a-4d1c-ef17-4e42bb17c78a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["!cp -r \"/content/drive/My Drive/recurrent-transformer-models/model_artifacts/StatefulTransformer_best_model.pth\" \"StatefulTransformer_best_model.pth\""],"metadata":{"id":"kswUXEPzSofZ","executionInfo":{"status":"ok","timestamp":1702494526235,"user_tz":300,"elapsed":1281,"user":{"displayName":"Christopher Hayduk","userId":"13984500138951800940"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["!rm -rf Recurrent-Neuron-Transformer"],"metadata":{"id":"3T2ns_Ynwcuj","executionInfo":{"status":"ok","timestamp":1702494526235,"user_tz":300,"elapsed":3,"user":{"displayName":"Christopher Hayduk","userId":"13984500138951800940"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["!git clone -b add-dev-container-debug-and-run-name https://github.com/ChrisHayduk/Recurrent-Neuron-Transformer.git"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-LOLNIUGyBY2","executionInfo":{"status":"ok","timestamp":1702494530363,"user_tz":300,"elapsed":4131,"user":{"displayName":"Christopher Hayduk","userId":"13984500138951800940"}},"outputId":"64d065cf-9077-431f-eb76-3ce2aa3a8a65"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'Recurrent-Neuron-Transformer'...\n","remote: Enumerating objects: 698, done.\u001b[K\n","remote: Counting objects: 100% (250/250), done.\u001b[K\n","remote: Compressing objects: 100% (140/140), done.\u001b[K\n","remote: Total 698 (delta 186), reused 166 (delta 109), pack-reused 448\u001b[K\n","Receiving objects: 100% (698/698), 27.82 MiB | 10.89 MiB/s, done.\n","Resolving deltas: 100% (443/443), done.\n"]}]},{"cell_type":"code","source":["!cd Recurrent-Neuron-Transformer/ && pip install -r requirements.txt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HnRgm5HXyCGA","executionInfo":{"status":"ok","timestamp":1702494536126,"user_tz":300,"elapsed":5764,"user":{"displayName":"Christopher Hayduk","userId":"13984500138951800940"}},"outputId":"8c812042-aa91-4fae-e3e1-0397b665397c"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers==4.34.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (4.34.1)\n","Requirement already satisfied: ipykernel==6.26.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (6.26.0)\n","Requirement already satisfied: pandas==2.1.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (2.1.2)\n","Requirement already satisfied: scikit-learn==1.3.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (1.3.2)\n","Requirement already satisfied: datasets==2.14.6 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (2.14.6)\n","Requirement already satisfied: tiktoken==0.5.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (0.5.2)\n","Requirement already satisfied: ipywidgets==8.1.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (8.1.1)\n","Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (0.16.1)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 9)) (3.7.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.34.1->-r requirements.txt (line 1)) (3.13.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers==4.34.1->-r requirements.txt (line 1)) (0.17.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.34.1->-r requirements.txt (line 1)) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.34.1->-r requirements.txt (line 1)) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.34.1->-r requirements.txt (line 1)) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.34.1->-r requirements.txt (line 1)) (2023.6.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.34.1->-r requirements.txt (line 1)) (2.31.0)\n","Requirement already satisfied: tokenizers<0.15,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers==4.34.1->-r requirements.txt (line 1)) (0.14.1)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.34.1->-r requirements.txt (line 1)) (0.4.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.34.1->-r requirements.txt (line 1)) (4.66.1)\n","Requirement already satisfied: comm>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from ipykernel==6.26.0->-r requirements.txt (line 2)) (0.2.0)\n","Requirement already satisfied: debugpy>=1.6.5 in /usr/local/lib/python3.10/dist-packages (from ipykernel==6.26.0->-r requirements.txt (line 2)) (1.6.6)\n","Requirement already satisfied: ipython>=7.23.1 in /usr/local/lib/python3.10/dist-packages (from ipykernel==6.26.0->-r requirements.txt (line 2)) (7.34.0)\n","Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.10/dist-packages (from ipykernel==6.26.0->-r requirements.txt (line 2)) (6.1.12)\n","Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /usr/local/lib/python3.10/dist-packages (from ipykernel==6.26.0->-r requirements.txt (line 2)) (5.5.0)\n","Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.10/dist-packages (from ipykernel==6.26.0->-r requirements.txt (line 2)) (0.1.6)\n","Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.10/dist-packages (from ipykernel==6.26.0->-r requirements.txt (line 2)) (1.5.8)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ipykernel==6.26.0->-r requirements.txt (line 2)) (5.9.5)\n","Requirement already satisfied: pyzmq>=20 in /usr/local/lib/python3.10/dist-packages (from ipykernel==6.26.0->-r requirements.txt (line 2)) (23.2.1)\n","Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.10/dist-packages (from ipykernel==6.26.0->-r requirements.txt (line 2)) (6.3.2)\n","Requirement already satisfied: traitlets>=5.4.0 in /usr/local/lib/python3.10/dist-packages (from ipykernel==6.26.0->-r requirements.txt (line 2)) (5.7.1)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas==2.1.2->-r requirements.txt (line 3)) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas==2.1.2->-r requirements.txt (line 3)) (2023.3.post1)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas==2.1.2->-r requirements.txt (line 3)) (2023.3)\n","Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.3.2->-r requirements.txt (line 4)) (1.11.4)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.3.2->-r requirements.txt (line 4)) (1.3.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.3.2->-r requirements.txt (line 4)) (3.2.0)\n","Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets==2.14.6->-r requirements.txt (line 5)) (10.0.1)\n","Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets==2.14.6->-r requirements.txt (line 5)) (0.3.7)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets==2.14.6->-r requirements.txt (line 5)) (3.4.1)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets==2.14.6->-r requirements.txt (line 5)) (0.70.15)\n","Requirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets==2.14.6->-r requirements.txt (line 5)) (2023.6.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets==2.14.6->-r requirements.txt (line 5)) (3.9.1)\n","Requirement already satisfied: widgetsnbextension~=4.0.9 in /usr/local/lib/python3.10/dist-packages (from ipywidgets==8.1.1->-r requirements.txt (line 7)) (4.0.9)\n","Requirement already satisfied: jupyterlab-widgets~=3.0.9 in /usr/local/lib/python3.10/dist-packages (from ipywidgets==8.1.1->-r requirements.txt (line 7)) (3.0.9)\n","Requirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb->-r requirements.txt (line 8)) (8.1.7)\n","Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb->-r requirements.txt (line 8)) (3.1.40)\n","Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb->-r requirements.txt (line 8)) (1.39.0)\n","Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb->-r requirements.txt (line 8)) (0.4.0)\n","Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb->-r requirements.txt (line 8)) (1.3.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb->-r requirements.txt (line 8)) (67.7.2)\n","Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb->-r requirements.txt (line 8)) (1.4.4)\n","Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb->-r requirements.txt (line 8)) (3.20.3)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 9)) (1.2.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 9)) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 9)) (4.46.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 9)) (1.4.5)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 9)) (9.4.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 9)) (3.1.1)\n","Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb->-r requirements.txt (line 8)) (1.16.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.14.6->-r requirements.txt (line 5)) (23.1.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.14.6->-r requirements.txt (line 5)) (6.0.4)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.14.6->-r requirements.txt (line 5)) (1.9.3)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.14.6->-r requirements.txt (line 5)) (1.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.14.6->-r requirements.txt (line 5)) (1.3.1)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.14.6->-r requirements.txt (line 5)) (4.0.3)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from GitPython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 8)) (4.0.11)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers==4.34.1->-r requirements.txt (line 1)) (4.5.0)\n","Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython>=7.23.1->ipykernel==6.26.0->-r requirements.txt (line 2)) (0.19.1)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=7.23.1->ipykernel==6.26.0->-r requirements.txt (line 2)) (4.4.2)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=7.23.1->ipykernel==6.26.0->-r requirements.txt (line 2)) (0.7.5)\n","Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=7.23.1->ipykernel==6.26.0->-r requirements.txt (line 2)) (3.0.41)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=7.23.1->ipykernel==6.26.0->-r requirements.txt (line 2)) (2.16.1)\n","Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=7.23.1->ipykernel==6.26.0->-r requirements.txt (line 2)) (0.2.0)\n","Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=7.23.1->ipykernel==6.26.0->-r requirements.txt (line 2)) (4.9.0)\n","Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel==6.26.0->-r requirements.txt (line 2)) (4.1.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.34.1->-r requirements.txt (line 1)) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.34.1->-r requirements.txt (line 1)) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.34.1->-r requirements.txt (line 1)) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.34.1->-r requirements.txt (line 1)) (2023.11.17)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 8)) (5.0.1)\n","Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel==6.26.0->-r requirements.txt (line 2)) (0.8.3)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel==6.26.0->-r requirements.txt (line 2)) (0.7.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=7.23.1->ipykernel==6.26.0->-r requirements.txt (line 2)) (0.2.12)\n"]}]},{"cell_type":"code","source":["import torch\n","from torch import nn\n","\n","class Neurons(nn.Module):\n","    def __init__(self, n_neurons, device):\n","        super(Neurons, self).__init__()\n","        self.device = device\n","\n","        # Initialize matrix neuron parameters and number of neurons to create\n","        self.n_neurons = n_neurons\n","        self.params = nn.Parameter(torch.rand(n_neurons, 3, 3) * 2 - 1)\n","        self.gelu = nn.GELU()\n","\n","    def forward(self, inputs, hidden_state=None):\n","        if hidden_state is not None:\n","            hidden_state = hidden_state.detach()\n","        else:\n","            hidden_state = torch.zeros(1, self.n_neurons, 1, device=self.device)\n","\n","        batch_size = inputs.shape[0]\n","        seq_len = inputs.shape[1]\n","\n","        hidden_batch = hidden_state.expand(batch_size, seq_len, self.n_neurons, 1)\n","        inputs = inputs.view(batch_size, seq_len, -1, 1)\n","        ones = torch.ones_like(inputs)\n","\n","\n","        # Concatenate along the last dimension\n","        stacked = torch.cat((inputs, hidden_batch, ones), dim=3)\n","\n","        # Reshape stacked for matrix multiplication: [batch_size, seq_len, n_neurons, 3]\n","        stacked = stacked.view(batch_size, seq_len, self.n_neurons, 3)\n","\n","        # Perform matrix multiplication\n","        dot = self.gelu(torch.matmul(self.params, stacked.unsqueeze(4)).squeeze(4))\n","\n","        # Update hidden state without in-place operation\n","        new_hidden = dot[:, :, :, 1].unsqueeze(3).detach()\n","\n","        return dot[:, :, :, 0], new_hidden\n","\n","class RecurrentNeuronLayer(nn.Module):\n","    def __init__(self, input_size, output_size, device):\n","        super(RecurrentNeuronLayer, self).__init__()\n","        self.neurons = Neurons(output_size, device)\n","        self.weights = nn.Linear(input_size, output_size)\n","        self.device = device\n","\n","    def forward(self, x, hidden_state=None):\n","        batch_size = x.shape[0]\n","        seq_len = x.shape[1]\n","\n","        x = self.weights(x)\n","        x, updated_hidden_state = self.neurons(x, hidden_state)\n","\n","        # Reshape the output to ensure it has the shape [batch_size, n_classes]\n","        final_output = x.view(batch_size, seq_len, -1)\n","\n","        return final_output, updated_hidden_state"],"metadata":{"id":"sihdB3XMy7Js","executionInfo":{"status":"ok","timestamp":1702494537647,"user_tz":300,"elapsed":1524,"user":{"displayName":"Christopher Hayduk","userId":"13984500138951800940"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import math\n","import torch\n","from torch import nn\n","import random\n","import torch.functional as F\n","from dataclasses import dataclass\n","\n","@dataclass\n","class RecurrentModelConfig:\n","    max_length: int = 1024\n","    vocab_size: int = 50304 # GPT-2 vocab_size of 50257, padded up to nearest multiple of 64 for efficiency\n","    n_layer: int = 12\n","    num_heads: int = 12\n","    hidden_dim: int = 768\n","    dropout: float = 0.0\n","    device: str = \"cuda\"\n","    recurrent_layers: str = \"all\"\n","\n","class MLP(nn.Module):\n","    def __init__(self, config):\n","        super().__init__()\n","        if \"proj\" == config.recurrent_layers or \"all\" == config.recurrent_layers:\n","            self.c_fc = RecurrentNeuronLayer(config.hidden_dim, 4 * config.hidden_dim, config.device)\n","        else:\n","            self.c_fc = nn.Linear(config.hidden_dim, 4 * config.hidden_dim)\n","\n","        self.gelu = nn.GELU()\n","\n","        if \"proj\" == config.recurrent_layers or \"all\" == config.recurrent_layers:\n","            self.c_proj = RecurrentNeuronLayer(4 * config.hidden_dim, config.hidden_dim, config.device)\n","        else:\n","            self.c_proj = nn.Linear(4 * config.hidden_dim, config.hidden_dim)\n","\n","        self.dropout = nn.Dropout(config.dropout)\n","\n","    def forward(self, x, hidden_layers = None, layer_num=0):\n","        if isinstance(self.c_fc, RecurrentNeuronLayer):\n","            x, hidden_layers[f\"c_fc_{layer_num}\"] = self.c_fc(x, hidden_layers.get(f\"c_fc_{layer_num}\"))\n","        else:\n","            x =  self.c_fc(x)\n","\n","        x = self.gelu(x)\n","\n","        if isinstance(self.c_proj, RecurrentNeuronLayer):\n","            x, hidden_layers[f\"c_proj_{layer_num}\"] = self.c_proj(x, hidden_layers.get(f\"c_proj_{layer_num}\"))\n","        else:\n","            x =  self.c_proj(x)\n","\n","        x = self.dropout(x)\n","        return x, hidden_layers\n","\n","class RecurrentCausalSelfAttention(nn.Module):\n","\n","    def __init__(self, config):\n","        super().__init__()\n","        assert config.hidden_dim % config.num_heads == 0\n","        # key, query, value projections for all heads, but in a batch\n","        if \"qkv\" == config.recurrent_layers or \"all\" == config.recurrent_layers:\n","            self.c_attn = RecurrentNeuronLayer(config.hidden_dim, 3 * config.hidden_dim, config.device)\n","        else:\n","            self.c_attn = nn.Linear(config.hidden_dim, 3 * config.hidden_dim)\n","        # output projection\n","\n","        if \"qkv\" == config.recurrent_layers or \"all\" == config.recurrent_layers:\n","            self.c_proj = RecurrentNeuronLayer(config.hidden_dim, config.hidden_dim, config.device)\n","        else:\n","            self.c_proj = nn.Linear(config.hidden_dim, config.hidden_dim)\n","\n","        # regularization\n","        self.attn_dropout = nn.Dropout(config.dropout)\n","        self.resid_dropout = nn.Dropout(config.dropout)\n","\n","        self.n_head = config.num_heads\n","        self.n_embd = config.hidden_dim\n","        self.dropout = config.dropout\n","        self.max_length = config.max_length\n","\n","        # flash attention make GPU go brrrrr but support is only in PyTorch >= 2.0\n","        self.flash = hasattr(torch.nn.functional, 'scaled_dot_product_attention')\n","        if not self.flash:\n","            print(\"WARNING: using slow attention. Flash Attention requires PyTorch >= 2.0\")\n","            # causal mask to ensure that attention is only applied to the left in the input sequence\n","            self.register_buffer(\"bias\", torch.tril(torch.ones(self.max_length, self.max_length))\n","                                        .view(1, 1, self.max_length, self.max_length))\n","\n","    def forward(self, x, hidden_layers=None, layer_num=0):\n","        B, T, C = x.size() # batch size, sequence length, embedding dimensionality (n_embd)\n","\n","        # calculate query, key, values for all heads in batch and move head forward to be the batch dim\n","        if isinstance(self.c_attn, RecurrentNeuronLayer):\n","            proj_output, hidden_layers[f\"c_attn_{layer_num}\"]  = self.c_attn(x, hidden_layers.get(f\"c_attn_{layer_num}\"))\n","        else:\n","            proj_output = self.c_attn(x)\n","\n","        q, k, v = proj_output.split(self.n_embd, dim=2)\n","        k = k.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n","        q = q.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n","        v = v.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n","\n","        # causal self-attention; Self-attend: (B, nh, T, hs) x (B, nh, hs, T) -> (B, nh, T, T)\n","        if self.flash:\n","            # efficient attention using Flash Attention CUDA kernels\n","            y = torch.nn.functional.scaled_dot_product_attention(q, k, v, attn_mask=None, dropout_p=self.dropout if self.training else 0, is_causal=True)\n","        else:\n","            # manual implementation of attention\n","            att = (q @ k.transpose(-2, -1)) * (1.0 / math.sqrt(k.size(-1)))\n","            att = att.masked_fill(self.bias[:,:,:T,:T] == 0, float('-inf'))\n","            att = F.softmax(att, dim=-1)\n","            att = self.attn_dropout(att)\n","            y = att @ v # (B, nh, T, T) x (B, nh, T, hs) -> (B, nh, T, hs)\n","        y = y.transpose(1, 2).contiguous().view(B, T, C) # re-assemble all head outputs side by side\n","\n","        # output projection\n","        if isinstance(self.c_proj, RecurrentNeuronLayer):\n","            y, hidden_layers[f\"c_proj_{layer_num}\"] = self.c_proj(y, hidden_layers.get(f\"c_proj_{layer_num}\"))\n","        else:\n","            y = self.c_proj(y)\n","\n","        y = self.resid_dropout(y)\n","        return y, hidden_layers\n","\n","class RecurrentTransformerBlock(nn.Module):\n","\n","    def __init__(self, config):\n","        super().__init__()\n","        self.ln_1 = nn.LayerNorm(config.hidden_dim)\n","        self.attn = RecurrentCausalSelfAttention(config)\n","        self.ln_2 = nn.LayerNorm(config.hidden_dim)\n","        self.mlp = MLP(config)\n","\n","    def forward(self, x, hidden_layers = None, layer_num = 0):\n","        new_x, hidden_layers = self.attn(self.ln_1(x), hidden_layers, layer_num)\n","        x = x + new_x\n","        new_x, hidden_layers = self.mlp(self.ln_2(x), hidden_layers, layer_num)\n","        x = x + new_x\n","        return x, hidden_layers\n","\n","class RecurrentNeuronTransformer(nn.Module):\n","    \"\"\"\n","    A single-layer Transformer which encodes a sequence of text and\n","    performs binary classification.\n","\n","    The model has a vocab size of V, works on\n","    sequences of length T, has an hidden dimension of H, uses word vectors\n","    also of dimension H, and operates on minibatches of size N.\n","    \"\"\"\n","    def __init__(self, config):\n","        \"\"\"\n","        :config\n","        \"\"\"\n","        super(RecurrentNeuronTransformer, self).__init__()\n","        assert config.hidden_dim % config.num_heads == 0\n","        assert config.recurrent_layers in set([\"qkv\", \"proj\", \"all\", \"none\"])\n","\n","        print(config)\n","\n","        self.num_heads = config.num_heads\n","        self.word_embedding_dim = config.hidden_dim\n","        self.hidden_dim = config.hidden_dim\n","        self.max_length = config.max_length\n","        self.vocab_size = config.vocab_size\n","        self.device = config.device\n","        self.dropout = config.dropout\n","\n","        self.transformer = nn.ModuleDict(dict(\n","            wte = nn.Embedding(self.vocab_size, self.word_embedding_dim),\n","            wpe = nn.Embedding(self.max_length, self.word_embedding_dim),\n","            drop = nn.Dropout(self.dropout),\n","            h = nn.ModuleList([RecurrentTransformerBlock(config) for _ in range(config.n_layer)]),\n","            ln_f = nn.LayerNorm(self.hidden_dim),\n","        ))\n","\n","\n","        self.lm_head = RecurrentNeuronLayer(self.hidden_dim, self.vocab_size, self.device)\n","\n","        # init all weights\n","        self.apply(self._init_weights)\n","        # apply special scaled init to the residual projections, per GPT-2 paper\n","        for pn, p in self.named_parameters():\n","            if pn.endswith('c_proj.weight'):\n","                torch.nn.init.normal_(p, mean=0.0, std=0.02/math.sqrt(2 * config.n_layer))\n","\n","        # report number of parameters\n","        print(\"Number of parameters: %.2fM\" % (self.get_num_params()/1e6,))\n","\n","    def get_num_params(self, non_embedding=True):\n","        \"\"\"\n","        Return the number of parameters in the model.\n","        For non-embedding count (default), the position embeddings get subtracted.\n","        The token embeddings would too, except due to the parameter sharing these\n","        params are actually used as weights in the final layer, so we include them.\n","        \"\"\"\n","        n_params = sum(p.numel() for p in self.parameters())\n","        if non_embedding:\n","            n_params -= self.transformer.wpe.weight.numel()\n","        return n_params\n","\n","    def _init_weights(self, module):\n","        if isinstance(module, RecurrentNeuronLayer):\n","            neuron_module = module.neurons\n","            torch.nn.init.normal_(neuron_module.params, mean=0.0, std=0.02)\n","            linear_module = module.weights\n","            torch.nn.init.normal_(linear_module.weight, mean=0.0, std=0.02)\n","            if linear_module.bias is not None:\n","                torch.nn.init.zeros_(linear_module.bias)\n","        elif isinstance(module, nn.Embedding):\n","            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n","\n","\n","    def forward(self, inputs, hidden_layers):\n","        \"\"\"\n","        This function computes the full Transformer forward pass.\n","        Put together all of the layers you've developed in the correct order.\n","\n","        :param inputs: a PyTorch tensor of shape (N,T). These are integer lookups.\n","\n","        :returns: the model outputs. Should be scores of shape (N,T,output_size).\n","        \"\"\"\n","\n","        embeddings = self.embed(inputs)\n","        x = self.transformer.drop(embeddings)\n","        for idx, block in enumerate(self.transformer.h):\n","            x, hidden_layers = block(x, hidden_layers, idx)\n","        x = self.transformer.ln_f(x)\n","        outputs, hidden_layers[\"lm_output\"] = self.lm_head(x, hidden_layers.get(\"lm_output\"))\n","\n","\n","        return outputs, hidden_layers\n","\n","\n","    def embed(self, inputs):\n","        \"\"\"\n","        :param inputs: intTensor of shape (N,T)\n","        :returns embeddings: floatTensor of shape (N,T,H)\n","        \"\"\"\n","\n","        pos = torch.arange(0, self.max_length, dtype=torch.long, device=self.device) # shape (t)\n","        tok_emb = self.transformer.wte(inputs) # token embeddings of shape (b, t, n_embd)\n","        pos_emb = self.transformer.wpe(pos) # position embeddings of shape (t, n_embd)\n","        embeddings  = tok_emb + pos_emb\n","\n","        return embeddings\n","\n","    @torch.no_grad()\n","    def generate(self, idx, max_new_tokens, hidden_layers = None, temperature=1.0, top_k=None):\n","        \"\"\"\n","        Take a conditioning sequence of indices idx (LongTensor of shape (b,t)) and complete\n","        the sequence max_new_tokens times, feeding the predictions back into the model each time.\n","        Most likely you'll want to make sure to be in model.eval() mode of operation for this.\n","        \"\"\"\n","        for _ in range(max_new_tokens):\n","            # if the sequence context is growing too long we must crop it at block_size\n","            idx_cond = idx if idx.size(1) <= self.config.block_size else idx[:, -self.config.block_size:]\n","            # forward the model to get the logits for the index in the sequence\n","            logits, hidden_layers = self(idx_cond, hidden_layers)\n","            # pluck the logits at the final step and scale by desired temperature\n","            logits = logits[:, -1, :] / temperature\n","            # optionally crop the logits to only the top k options\n","            if top_k is not None:\n","                v, _ = torch.topk(logits, min(top_k, logits.size(-1)))\n","                logits[logits < v[:, [-1]]] = -float('Inf')\n","            # apply softmax to convert logits to (normalized) probabilities\n","            probs = F.softmax(logits, dim=-1)\n","            # sample from the distribution\n","            idx_next = torch.multinomial(probs, num_samples=1)\n","            # append sampled index to the running sequence and continue\n","            idx = torch.cat((idx, idx_next), dim=1)\n","\n","        return idx"],"metadata":{"id":"GI81tIH3ya-J","executionInfo":{"status":"ok","timestamp":1702494537647,"user_tz":300,"elapsed":3,"user":{"displayName":"Christopher Hayduk","userId":"13984500138951800940"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["import torch\n","from torch.utils.data import Dataset, DataLoader\n","import numpy as np\n","import tiktoken\n","import os\n","\n","class TextDataset(Dataset):\n","    def __init__(self, tokens, seq_length, bpe_tokenizer, vocab_size, device):\n","        self.tokens = tokens\n","        self.tokenizer = tiktoken.get_encoding(bpe_tokenizer)\n","        self.seq_length = seq_length\n","        self.vocab_size = vocab_size\n","        self.device = device\n","\n","    def __len__(self):\n","        return len(self.tokens) - self.seq_length - 1\n","\n","    def __getitem__(self, idx):\n","        input_seq = torch.tensor(self.tokens[idx : idx+self.seq_length], device=self.device)\n","        target_seq = torch.tensor(self.tokens[idx+1 : idx+1+self.seq_length], device=self.device)\n","        return input_seq, target_seq\n","\n","\n","class TextDataLoader:\n","    def __init__(self, file_path, seq_length, bpe_tokenizer, batch_size, vocab_size, device, split_ratio=0.8):\n","        self.file_path = file_path\n","        self.seq_length = seq_length\n","        self.bpe_tokenizer = bpe_tokenizer\n","        self.batch_size = batch_size\n","        self.vocab_size = vocab_size\n","        self.device = device\n","        self.split_ratio = split_ratio\n","\n","    def load_and_tokenize(self):\n","        try:\n","            with open(self.file_path, 'r', encoding='utf-8') as f:\n","                text = f.read()\n","            return text\n","        except IOError:\n","            print(f\"Error opening/reading {self.file_path}\")\n","            return None\n","\n","    def _create_datasets(self):\n","        text = self.load_and_tokenize()\n","        tokenizer = tiktoken.get_encoding(self.bpe_tokenizer)\n","        tokens = tokenizer.encode_ordinary(text)\n","        split_index = int(len(tokens) * self.split_ratio)\n","        train_tokens = tokens[:split_index]\n","        test_tokens = tokens[split_index:]\n","        train_dataset = TextDataset(train_tokens, self.seq_length, self.bpe_tokenizer, self.vocab_size, self.device)\n","        test_dataset = TextDataset(test_tokens, self.seq_length, self.bpe_tokenizer, self.vocab_size, self.device)\n","        return train_dataset, test_dataset\n","\n","    def create_loaders(self):\n","        train_dataset, test_dataset = self._create_datasets()\n","        train_loader = DataLoader(train_dataset, batch_size=self.batch_size, shuffle=True, drop_last=True)\n","        test_loader = DataLoader(test_dataset, batch_size=self.batch_size, shuffle=False, drop_last=True)\n","        return train_loader, test_loader\n"],"metadata":{"id":"4T4Joa1U04DC","executionInfo":{"status":"ok","timestamp":1702494537648,"user_tz":300,"elapsed":3,"user":{"displayName":"Christopher Hayduk","userId":"13984500138951800940"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["# Device configuration\n","if torch.cuda.is_available():\n","    DEVICE = torch.device('cuda')\n","elif torch.backends.mps.is_available():\n","    DEVICE = torch.device('mps')\n","else:\n","    DEVICE = torch.device('cpu')\n","print(f\"Using device: {DEVICE}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4toiz88KzeFP","executionInfo":{"status":"ok","timestamp":1702494538320,"user_tz":300,"elapsed":4,"user":{"displayName":"Christopher Hayduk","userId":"13984500138951800940"}},"outputId":"3f3906a2-084f-437b-8be5-6ae4004a9c01"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cuda\n"]}]},{"cell_type":"code","source":["model_config = RecurrentModelConfig(max_length=512, vocab_size=50257,\n","                                    n_layer=8, num_heads=8, hidden_dim=768,\n","                                    dropout=0.1, device=DEVICE, recurrent_layers=\"all\")\n","\n","model = RecurrentNeuronTransformer(config=model_config).to(DEVICE)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PiZaIDtGyEox","executionInfo":{"status":"ok","timestamp":1702494542089,"user_tz":300,"elapsed":3771,"user":{"displayName":"Christopher Hayduk","userId":"13984500138951800940"}},"outputId":"946c6aed-162a-47d4-888c-8d03349345aa"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["RecurrentModelConfig(max_length=512, vocab_size=50257, n_layer=8, num_heads=8, hidden_dim=768, dropout=0.1, device=device(type='cuda'), recurrent_layers='all')\n","Number of parameters: 134.90M\n"]}]},{"cell_type":"code","source":["model.load_state_dict(torch.load('StatefulTransformer_best_model.pth'))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AmGZM50v0LwA","executionInfo":{"status":"ok","timestamp":1702494542632,"user_tz":300,"elapsed":545,"user":{"displayName":"Christopher Hayduk","userId":"13984500138951800940"}},"outputId":"c6f7c970-9a25-48ea-ba37-6896ba353bf1"},"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["data_loader = TextDataLoader(file_path=\"Recurrent-Neuron-Transformer/data/shakespeare/tinyshakespeare.txt\",\n","                             seq_length=4096,\n","                             bpe_tokenizer='gpt2',\n","                             batch_size=12,\n","                             vocab_size=50257,\n","                             split_ratio=0.8,\n","                             device=DEVICE)\n","train_loader, test_loader = data_loader.create_loaders()"],"metadata":{"id":"YGiQ8lyO0VLQ","executionInfo":{"status":"ok","timestamp":1702494543090,"user_tz":300,"elapsed":460,"user":{"displayName":"Christopher Hayduk","userId":"13984500138951800940"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["def recurrent_transformer_forward(model, input_seq, hidden_layers, target_seq):\n","    # Forward pass\n","    outputs, hidden_layers = model(inputs=input_seq, hidden_layers=hidden_layers)\n","    outputs = outputs.reshape(-1, outputs.size(-1))\n","    target_seq = target_seq.reshape(-1)\n","\n","    # Calculate loss\n","    loss = nn.CrossEntropyLoss()(outputs, target_seq)\n","\n","    return (outputs, hidden_layers), loss"],"metadata":{"id":"LdMeQXUd3Y8Z","executionInfo":{"status":"ok","timestamp":1702494543091,"user_tz":300,"elapsed":3,"user":{"displayName":"Christopher Hayduk","userId":"13984500138951800940"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["import wandb\n","\n","wandb.init(\n","    # set the wandb project where this run will be logged\n","    project=\"transformer-testing\",\n",")\n","\n","wandb.run.name = \"StatefulTransformer_Stepwise-Eval\"\n","wandb.define_metric(\"eval_batch\")\n","\n","wandb.define_metric(\"epoch/*\", step_metric=\"epoch\")\n","wandb.define_metric(\"eval_batch/*\", step_metric=\"eval_batch\")\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":139},"id":"RUeLqLN9_WnW","executionInfo":{"status":"ok","timestamp":1702494548622,"user_tz":300,"elapsed":5533,"user":{"displayName":"Christopher Hayduk","userId":"13984500138951800940"}},"outputId":"6640f7c2-1ab7-4621-d8f6-61f26c0bcba7"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mchayduk\u001b[0m (\u001b[33mrecurrent-neuron-transformer\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.16.1"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20231213_190906-ugpy3nfo</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/recurrent-neuron-transformer/transformer-testing/runs/ugpy3nfo' target=\"_blank\">skilled-thunder-169</a></strong> to <a href='https://wandb.ai/recurrent-neuron-transformer/transformer-testing' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/recurrent-neuron-transformer/transformer-testing' target=\"_blank\">https://wandb.ai/recurrent-neuron-transformer/transformer-testing</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/recurrent-neuron-transformer/transformer-testing/runs/ugpy3nfo' target=\"_blank\">https://wandb.ai/recurrent-neuron-transformer/transformer-testing/runs/ugpy3nfo</a>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["<wandb.sdk.wandb_metric.Metric at 0x7daa409e8130>"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["from tqdm import tqdm\n","\n","context_window = 512\n","step_size = 511\n","distributed = False\n","rank = 0\n","\n","\n","model.eval()\n","epoch_val_loss = 0\n","eval_progress_bar = tqdm(test_loader, desc=f'Evaluating: Epoch 1', leave=False)\n","num_steps = (4096/511)\n","\n","if int(num_steps) < num_steps:\n","  num_steps = int(num_steps) + 1\n","else:\n","  num_steps = int(num_steps)\n","\n","step_losses = [0] * num_steps\n","raw_losses = [0] * num_steps\n","with torch.no_grad():\n","    for batch_idx, (input_chunk, target_chunk) in enumerate(eval_progress_bar):\n","        batch_loss = 0\n","        hidden_layers = dict()\n","\n","        for i in range(0, input_chunk.size(1) - context_window, step_size):\n","            index = i//step_size\n","            # Create the input and target sequences\n","            input_seq = input_chunk[:, i:i+context_window].to(DEVICE)\n","            target_seq = target_chunk[:, i+1:i+context_window+1].to(DEVICE)\n","\n","            outputs = None\n","            loss = None\n","            (outputs, hidden_layers), loss = recurrent_transformer_forward(model, input_seq, hidden_layers, target_seq)\n","\n","            batch_loss += loss.item()\n","\n","            raw_losses[index] += loss.item()\n","\n","            step_losses[index] = raw_losses[index] / (batch_idx + 1)\n","\n","            if (rank == 0 or not distributed):\n","                wandb.log({'eval_batch': batch_idx, f'eval_batch/step_{index}_loss': loss.item()})\n","                wandb.log({'eval_batch': batch_idx, f'eval_batch/step_{index}_average_loss': step_losses[index]})\n","\n","        epoch_val_loss += batch_loss\n","        eval_progress_bar.set_postfix(loss=batch_loss)\n","\n","avg_val_loss = epoch_val_loss / len(test_loader)\n","\n","wandb.log({'epoch': 1, 'epoch/val_loss': avg_val_loss})\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zucLJi291io9","outputId":"2063343a-17b3-426a-acec-2323008e148b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Evaluating: Epoch 1:  77%|███████▋  | 4054/5292 [7:42:08<2:21:08,  6.84s/it, loss=143]"]}]},{"cell_type":"code","source":["torch.cuda.empty_cache()"],"metadata":{"id":"Wn5bsaEL36MO"},"execution_count":null,"outputs":[]}]}